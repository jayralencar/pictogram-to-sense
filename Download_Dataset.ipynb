{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Download Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl8_BSpRJ-2s"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github//jayralencar/pictogram-to-sense/blob/main/Download_Dataset.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/jayralencar/pictogram-to-sense/blob/main/Download_Dataset.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/drive/1wLgg4CtmR1ZJ2bMTWN5dcsamw8ZOAdN0\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9BqbgDYHeLv"
      },
      "source": [
        "# Dowload ARASAAC\n",
        "\n",
        "The aim of this Notebook is to download the pictograms from [ARASAAC](http://arasaac.org/) to be used as a dataset for fine-tuning CLIP.\n",
        "\n",
        "In our case, fine-tuning CLIP consists of adjusting its parameters using a pictogram dataset. \n",
        "For this, we need a dataset of pictograms paired with their textual description.\n",
        "In addition to keywords, ARASAAC has a meaning text for some pictograms. This way, we used the pictograms from ARASAAC and their descriptions to make (image, text) pairs and used them as a dataset. For this, we used the ARASAAC developers API to download the image and description of all the available pictograms. When the pictogram has two or more descriptions, we copy the image as many times as necessary and pair each copy with its respective description. After this procedure, we acquired 22,448 (image, text) pairs, which we split in 80\\% for training and 20\\% for validation. \n",
        "\n",
        "Download the dataset [here](https://drive.google.com/file/d/1P627Qusf8QmaVvrEoevWJNjuUp2luOyd/view), or execute the cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FbyOVRcXdYU"
      },
      "source": [
        "% mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgrX5B30Xm1P"
      },
      "source": [
        "import urllib\n",
        "import requests\n",
        "\n",
        "def download_image(pictogram_id, names=[],details=None):\n",
        "  if details is None:\n",
        "    url = \"https://api.arasaac.org/api/pictograms/\"+str(pictogram_id)+\"?download=true\"\n",
        "    filename = 'data/'+str(pictogram_id)+\".png\"\n",
        "  else:\n",
        "    details['download']='true'\n",
        "    url = \"https://api.arasaac.org/api/pictograms/{0}?\".format(pictogram_id)+urllib.parse.urlencode(details)\n",
        "    print(url)\n",
        "    filename = 'data/{0}_{1}_{2}.png'.format(pictogram_id,details['skin'],details['hair'])\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  for filename in names:\n",
        "    open(\"data/\"+filename+'.png', 'wb').write(r.content)\n",
        "# download_image(4665,names=['a','b'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwkfBwHBXIVQ"
      },
      "source": [
        "r = requests.get(\"https://api.arasaac.org/api/pictograms/all/en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXDb5j9jXNGb",
        "outputId": "a6992ff7-75cc-4847-fa85-3af3e97d11ab"
      },
      "source": [
        "import string\n",
        "from tqdm import tqdm\n",
        "for pictogram in tqdm(r.json()):\n",
        "  definition = None\n",
        "  names = []\n",
        "  i = 1\n",
        "  for kw in pictogram['keywords']:\n",
        "    if 'meaning' in kw:\n",
        "      definition = \"{0}: {1}\".format(kw['keyword'],kw['meaning'])\n",
        "    else:\n",
        "      definition = kw['keyword']\n",
        "    open(\"./data/{0}_{1}.txt\".format(pictogram['_id'],i),'w').write(definition)\n",
        "    names.append(\"{0}_{1}\".format(pictogram['_id'],i))\n",
        "    i+=1\n",
        "  download_image(pictogram['_id'],names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11779/11779 [1:21:04<00:00,  2.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPr09D7NZLp_"
      },
      "source": [
        "!zip data.zip -r ./data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}